{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En <b>gras</b> les titres de parties ou les mots importants<br>\n",
    "En <font color='red'>rouge</font> les théorèmes ou définitions<br>\n",
    "En <font color='blue'>bleu</font> les rappels<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>09/09</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rappels stats & proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Grandeurs empiriques VS grandeurs théoriques</u><br>\n",
    "<u>Modèle statistique</u><br>\n",
    "<u>Modèle statistique paramétrique</u><br>\n",
    "<u>Estimation</u><br>\n",
    "<u>Risque quadratique</u><br>\n",
    "<u>Statistiques exploratoires et descriptives</u><br>\n",
    "<u>Variance / écart type</u><br>\n",
    "<u>Estimation par noyau (KDE)</u><br>\n",
    "<u>Fonction de répartition</u><br><br>\n",
    "<u>Fonction quantile</u><br>\n",
    "$\\mathbb{P}(X<q_{\\alpha})=\\alpha$<br><br>\n",
    "<u>Corrélation empirique</u><br>\n",
    "<u>Matrice de covariance</u><br>\n",
    "<font color='red'><u>Théorème spectral</u><br>\n",
    "Si $M$ est une matrice symétrique à coefficients réels, <br> alors il existe une matrice $U$ orthogonale et une matrice $D$ diagonale à coefficients réels tel que:<br> $M=UDU^{-1}$ <br></font>\n",
    "Si $M \\in \\mathbb{R}^n$,<br>\n",
    "$U=(U_1|...|U_n)$ vecteurs propres de $M$<br>\n",
    "$D=\\begin{pmatrix}\n",
    "\\lambda_1 & . & . \\\\\n",
    ". & \\ddots & . \\\\\n",
    ". & . & \\lambda_n\n",
    "\\end{pmatrix}$ valeurs propres de $M$<br>\n",
    "On peut retrouver le théorème avec la définition d'une valeur propre:<br>\n",
    "$\\lambda$ est valeur propre de $A$ s'il existe un vecteur propre $u$ non nul tel que $Mu=\\lambda u$<br>\n",
    "En utilisant $U$ et $D$ comme définis plus hauts,<br>\n",
    "$MU=UD$<br>\n",
    "$=>M=UDU^{-1}$<br>\n",
    "$=>M=UDU^T$<br>\n",
    "<font color='blue'>\n",
    "$U$ matrice orthogonale:<br>\n",
    "    *$U$ est inversible et $U^{-1}=U^T$<br>\n",
    "    *$U^TU=I$<br>\n",
    "    *Tous les vecteurs colonnes de $U$ sont orthogonaux et de norme 1. Ainsi, les colonnes de $U$ forment une base orthonormée.<br>\n",
    "</font>\n",
    "<u>Loi normale unidimensionnel</u><br>\n",
    "<u>Vecteurs gaussiens</u><br>\n",
    "<u>Propriétés des vecteurs gaussiens</u><br>\n",
    "<u>Cholesky</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>16/09</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle linéaire en dimension 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modélisation (équation)<br>\n",
    "Règle de Fermat / CNO<br>\n",
    "Expressions des coefficients<br>\n",
    "Centrage + mise à l'échelle<br>\n",
    "Prédicteur<br>\n",
    "Résidus<br>\n",
    "Vraisemblance<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle linéaire multivarié"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modélisation (équation)<br>\n",
    "Optimisation avec méthode du gradient<br>\n",
    "Unicité<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>23/09</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/Thm de projection<br>\n",
    "<font color = 'red'>Thm de projection (Hilbert): soit $\\mathcal{F} \\subset \\mathbb{R^n}$ et $y \\subset \\mathbb{R^n}$<br>\n",
    "Il est existe un unique point $z$ tel que: $\\inf_{z \\in \\mathcal{F}}||y-z||^2_2$<br>\n",
    "Ce point est caractérisé par les équations normales: <br>\n",
    "$<f,y-z>=0, \\forall f \\in \\mathcal{F}$</font>\n",
    "\n",
    "(schéma projection)\n",
    "\n",
    "Application aux MCO<br>\n",
    "Dans le cas des MCO on a un unique point $\\inf||Y-X\\theta||_2^2$ caractérisé par les équations normales:<br>\n",
    "$<X,Y-X\\theta>=0$\n",
    "\n",
    "(schéma projection)\n",
    "\n",
    "Thm unicité de l'estimateur<br><br>\n",
    "2/ Normalisation - centralisation des données<br><br>\n",
    "a) Modèle avec intercept<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$argmin \\|Y-1\\theta_0-\\tilde{X}\\theta\\|^2_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Modèle centré et sans intercept\n",
    "\n",
    "==> a) et b) équivalent, relation entre les estimateurs (formule)\n",
    "\n",
    "NORMALISATION : centrage + rescaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Etude théorique des MCO dans le cas du \"fixed design\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suppose:\n",
    "$$\n",
    "Y=X\\theta^* +\\epsilon \\\\\n",
    "avec~\\epsilon \\in \\mathbb{R}^n \\\\\n",
    "X~déterministe \\\\\n",
    "\\epsilon_i~indépendantes,~centrées~(\\mathbb{E}[\\epsilon]=0) \\\\\n",
    "\\\\~\\\\\n",
    "\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        cov(\\epsilon)=\\sigma^2I_n \\\\\n",
    "        \\mathbb{E}[\\epsilon]=0\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biais et Variance des coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Var[\\widehat{\\theta_n}]=\\sigma^2(X^TX)^{-1}$\n",
    "\n",
    "$R_{quad}[\\widehat{\\theta_n}]=Tr(Cov(\\widehat{\\theta_n}))+\\||Biais(\\widehat{\\theta_n})||_2^2\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas où le biais est nul:\n",
    "\n",
    "$R_{quad}[\\widehat{\\theta_n}]=Tr(Cov(\\widehat{\\theta_n}))=\\sigma^2(X^TX)^{-1}=\\frac{\\sigma^2}{n}Tr(\\widehat{G}^{-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Problème de conditionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_{pred}[\\widehat{\\theta_n}]=\\sigma^2*rang(H_X)$\n",
    "\n",
    "avec    $H_X=X(X^TX)^{-1}X^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>30/09</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul / estimation de $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbb{E}[\\sum{\\widehat{\\epsilon}^2}]=\\sigma^2(n-(p+1))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Modèle sous-gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suppose:\n",
    "$$\n",
    "Y=X\\theta^* +\\epsilon \\\\\n",
    "avec~\\epsilon \\in \\mathbb{R}^n \\\\\n",
    "X~déterministe \\\\\n",
    "\\epsilon_i~indépendantes,~centrées,~\\textbf{sous-gaussiennes} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Une variable centrée Z est dit <b>sous-gaussienne</b> si:\n",
    "$$\\forall \\lambda \\in \\mathbb{R},~\\mathbb{E}[e^{\\lambda Z}]\\le e^{\\frac{\\lambda^2 \\sigma^2}{2}}$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Inégalité de Markov:\n",
    "soit X une VA positive ou nulle presque sûrement, alors:\n",
    "$$\\forall~a>0,~(|X|\\ge a)\\le\\frac{\\mathbb{E}[X]}{a}$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les inégalités de concentration fournissent des bornes aux VA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant Markov:\n",
    "\n",
    "<font color='red'>Inégalités de concentration:\n",
    "    \n",
    "$\\mathbb{P}(|S_n|>t)\\le 2e^{-\\frac{t^2}{2v_n}} \\\\\n",
    "avec~v_n=\\sum{\\sigma_i^2}$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$|\\widehat{\\theta}_{n,k}-\\theta^*_k|\\le \\sqrt{\\frac{2\\sigma^2log(2/\\sigma)}{n\\lambda_n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Modèle gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suppose:\n",
    "$$\n",
    "Y=X\\theta^* +\\epsilon \\\\\n",
    "X~déterministe \\\\\n",
    "\\epsilon_i~indépendantes,~centrées,~\\textbf{gaussiennes} \\\\\n",
    "\\mathbb{V}[\\epsilon_i]=\\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>Théorème de Cochran:\n",
    "soient $Q_i$ des formes quadratiques sur Y tel que $\\sum{Q_i}=\\sum Y_i^2$.\n",
    "\n",
    "Alors:\n",
    "\n",
    "$Q_j \\perp \\!\\!\\! \\perp ~~ et ~~ Q_j\\sim\\chi^2~~\\forall j$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du théorème de Cochran il en découle:\n",
    "\n",
    "(i) $\\widehat{\\theta}_{n,k} \\perp \\!\\!\\! \\perp \\widehat{\\sigma}^2_n~avec~\\widehat{\\sigma}^2_n=\\frac{1}{n-p-1}\\sum{}\\widehat{\\epsilon}^2_i$\n",
    "\n",
    "(ii) $\\sqrt{n}(\\widehat{\\theta}_n-\\theta^*)\\sim \\mathcal{N}(0,(X^TX)^{-1}\\sigma^2)$\n",
    "\n",
    "(iii) $\\widehat{\\sigma}^2_n \\frac{n-p-1}{\\sigma^2}\\sim \\chi^2(n-p-1)$\n",
    "\n",
    "(iv) $\\sqrt{\\frac{n}{\\widehat{\\sigma}^2 S_{n,k}}}(\\widehat{\\theta}_n-\\theta^*) \\sim T(n-p-1)~avec~S_{n,k}=e^T_k\\widehat{G}_ne_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>07/10</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALLES DE CONFIANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS PARAMETRIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a $X_1,...,X_n~(iid)\\sim \\mathbb{P_\\theta}$ <br>\n",
    "\n",
    "$\n",
    "\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        H_0: \\theta=a \\\\\n",
    "        H_1: \\theta=b \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$\n",
    "<br>\n",
    "(On suppose ici que $a<b$)\n",
    "\n",
    "On choisit l'estimateur de la moyenne empirique: $\\widehat{\\theta}=\\frac{1}{n}\\sum{X_i}$ <br>\n",
    "On fixe $k$ pour un niveau de rejet $\\alpha$ et une zone de rejet:<br>\n",
    "$Z=\\{\\widehat{\\theta} \\ge k\\}$ (sous $H_1$, $\\widehat{\\theta}$ est grand)\n",
    "\n",
    "On cherche $k$ défini tel que:<br>\n",
    "$\\mathbb{P_{\\theta\\ \\in \\Theta_0}}(\\widehat{\\theta} \\ge k)=\\alpha$ => sous $H_0$, on ne rejette l'hypothèse $H_0$ que lorsque notre estimateur $\\widehat{\\theta}$ est supérieur à $k$\n",
    "\n",
    "On centre et réduit pour utiliser le retrouver la loi normale:\n",
    "\n",
    "$\\mathbb{P_{\\theta\\ \\in \\Theta_0}}(U \\ge \\frac{\\sqrt{n} (k-\\theta)}{\\sqrt{\\sigma^2}})=\\alpha$ avec $U \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "Ainsi, $\\frac{\\sqrt{n} (k-\\theta)}{\\sqrt{\\sigma^2}}=q_\\alpha$ => on peut trouver $k$ qui nous dit quand rejeter $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Dans l'exemple ci-dessous, la valeur de $\\widehat{\\theta}$ ne nous permet pas de rejeter l'hypothèse $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tests1.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tests2.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>14/10</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE BOOTSTRAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Boostrap</i>: get oneself into a situation using <b>existing resources.</b><br>\n",
    "=> Méthode de réechantillonage utilisant le <b>tirage avec remise</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Principe du plug-in</font>: approcher une distribution inconnue par une <b>distribution empirique</b> évaluée sur un échantillon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La racine statistique est $\\hat{R}$ une fonction de $(X_1,...,X_n)$ qui converge en distribution vers $G$, i.e. $\\hat{R}\\sim G$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche donc la distribution de: $\\hat{R}=\\sqrt{n}(\\widehat{\\theta}-\\theta_{0})=\\sqrt{n}(T(\\mathbb{P_n})-T(\\mathbb{P}))$ où $T(\\mathbb{P_n})$ est une transformation de la distribution inconnue faisant intervenir la distribution empirique.<br>\n",
    "Rappel: $\\theta_0$ est la <b>vraie</b> quantité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après le TCL, on a la convergence:<br>\n",
    "$$\\sqrt{n}(\\widehat{\\theta}-\\theta_{0})\\sim \\mathcal{N}(0,v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problèmes</b>:<br>\n",
    "On ne connaît pas le n optimal<br>\n",
    "La variance peut être dure à calculer<br>\n",
    "Sous le modèle gaussien, les ICs peuvent être biaisés<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solution</b>:<br>\n",
    "On utilise le bootstrap pour simuler la loi de $\\sqrt{n}(T(\\mathbb{P_n})-T(\\mathbb{P}))$: <br><br>\n",
    "for b:1...B: <br>\n",
    "$(X_i)^* \\sim \\mathbb{P_n}$<br>\n",
    "Calcul de $T(\\mathbb{P_n^*})$<br>\n",
    "$R_b^*=\\sqrt{n}(T(\\mathbb{P_n^*})-T(\\mathbb{P_n}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(R_b^*)_{b=1...B}$ est l'échantillon Bootstrap qui simule la loi de $\\sqrt{n}(T(\\mathbb{P_n})-T(\\mathbb{P}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>21/10</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappels diagonalisation et SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel du théorème spectral: $M=UDU^T$<br>\n",
    "En général on trie les valeurs propres par ordre décroissant: $\\lambda_1 \\ge \\lambda_2 \\ge ... \\ge \\lambda_p \\ge 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>Singular Value Decomposition <br>\n",
    "C'est une généralisation de la diagonalisation pour n'importe quelle matrice.\n",
    "SVD: soit $X \\in \\mathbb{R^{nxp}}$ à coefficients réels, alors $X=VDU^T$ avec:\n",
    "$\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        V \\in \\mathbb{R^{nxr}} \\\\\n",
    "        S=diag(S_1,...,S_r) \\\\\n",
    "        U \\in \\mathbb{R^{pxr}}\n",
    "    \\end{array}\n",
    "\\right.$<br>\n",
    "et $U^TU=V^TV=I_r$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problèmes de OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Non-unicité de $\\widehat{\\theta_n}$: on peut appliquer la méthode avec l'inverse généralisé $(X^TX)^{+}X^TY$<br>\n",
    "(ii) Valeurs propres très petites mais non nulles<br>\n",
    "(iii) Problème statistique lié à la présence de petites valeurs propres (variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\widehat{\\theta^{Ridge}_{n,\\lambda}}=((X^TX)-\\lambda I)^{-1}X^TY$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
