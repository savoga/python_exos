HADOOP

Système de traitement de données réparti en plusieurs noeuds

Principe de base: haute tolérance aux pannes

HDFS: système de fichiers distibués. Les données sont réparties et répliquées sur le cluster.
MapReduce: paradigme de programmation. C'est une façon de construire des applications distribuées.
YARN: gestionnaire de ressources. Permet de lancer des applications sur le cluster. Parmi ses composantes:
- Resource manager: gère l'ensemble des ressources pour tout le cluster
- Application master: gère les ressources pour une application, négocie ses ressources au RM
- Node manager: monitore les ressources par machine, reporte les informations au RM
fsImage: fichier qui contient les infos de la localisation d'un bloc de données
editLog: fichier qui contient les infos des derniers changements sur les données

Configuration par défaut:
Stockage par bloc de 64Mo
Facteur de réplication = 3

Noeuds master (décident du lieu d'écriture): 
- primary namenode: récupère les fsImage et editLog du client
- secondary namenode: fusionne les fsImage et editLog du client pour en faire un fichier .checkpoint
Noeuds workers:
- datanode

Panne: 
- Un datanode tombe: si le namenode ne recoit plus de heartbeat pendant une certaine durée, les données sont répliquées depuis des copies d'autres datanodes
- Un namenode tombe: le namenode secondaire gère toutes les intéractions avec le cluster


SPARK

Outil de processing et d'analyse de données à grande échelle, codé en Scala, et en open source

++: fonctionne sur un laptop en local (sans cluster manager)
++: stockage des données en RAM (et non sur disque comme Hadoop) = mise en cache des données => accès plus rapide

Utilise une VM

Deux masters
Un job est exécuté par un groupe de workers (plusieurs executors et un driver)

Cluster manager = service externe regroupant l’ensemble des ressources du cluster (i.e. standalone manager, Mesos, YARN)
Master node = noeud sur lequel est installé le cluster manager en mode Standalone (i.e installé sur des conteneurs => plusieurs VM)
Worker node = noeud mis à disposition dans le cluster pour faire tourner une application

Driver program = processus sur lequel tourne le main() de l’application. Il crée le SparkContext
Executor = processus lancé pour une application sur un Worker node. C’est le processus qui exécute les tâches “lourdes” de l’application et stocke en mémoire les résultats intermédiaires.
Application = Application Spark. Elle est constituée d’un driver et d’executors. 
Job = un calcul parallélisé au sein d’une application consistant en un ensemble de stages menant à une Action (ex : collect)
Stage = ensemble de tasks interdépendantes (ex : map puis reduce)
Task = unité de travail distribuée sur un executor

HIVE

Outils permettant le requêtage et l'analyse de données. S'utilise avec Hadoop.
Langage proche du SQL
Stockage à la manière d'un stockage relationnel

++ utilise MapReduce pour les requêtes

MINIO

Service de stockage en ligne (cloud). Alternative à Hadoop, même si Minio est davantage centré sur le Cloud.

Ce n'est pas un grand système de stockage mais une solution pour avoir les données proches des applications.
Peut être utilisé avec un "vrai" système de stockage tel que S3

++ open source, très facile d'utilisation
